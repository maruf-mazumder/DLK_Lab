{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAEh3ZyOZwL",
        "outputId": "73909382-180d-42b8-dbf1-aed45b295156"
      },
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-07 19:04:44--  https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.12.207, 108.177.13.207, 74.125.26.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.12.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228813984 (218M) [application/x-compressed-tar]\n",
            "Saving to: ‘flower_photos.tgz’\n",
            "\n",
            "flower_photos.tgz   100%[===================>] 218.21M   234MB/s    in 0.9s    \n",
            "\n",
            "2023-12-07 19:04:45 (234 MB/s) - ‘flower_photos.tgz’ saved [228813984/228813984]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a8aYj8TPWWc",
        "outputId": "a335dec5-fec4-4e77-8fa4-0d240c662da3"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mahotas) (1.23.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K9NXmJ-OezW"
      },
      "source": [
        "!tar -xzvf \"flower_photos.tgz\" -C \".\" > xx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifSEJ0ANOnlF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import sklearn\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P6Y1sz2O59F",
        "outputId": "6f8e8d38-ddcb-4a01-cb57-9443f8327272"
      },
      "source": [
        "def load_img(indir):\n",
        "    samples = []\n",
        "    labels = []\n",
        "    for class_dir in os.listdir(indir):\n",
        "        if not os.path.isdir(indir+'/'+class_dir):\n",
        "          continue\n",
        "        print(\"Loading:\",class_dir)\n",
        "        the_class = class_dir\n",
        "        for file in os.listdir(indir+'/'+class_dir):\n",
        "            image = cv2.imread(\"{}/{}/{}\".format(indir,class_dir,file))\n",
        "            image = cv2.resize(image, (64,64))\n",
        "            samples.append(image)\n",
        "            labels.append(the_class)\n",
        "    samples = np.array(samples)\n",
        "    labels = np.array(labels)\n",
        "    return samples,labels\n",
        "samples, labels = load_img('flower_photos')\n",
        "print('loaded',len(samples),' samples')\n",
        "print('classes',set(labels))\n",
        "org_samples = samples\n",
        "org_labels = labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: daisy\n",
            "Loading: sunflowers\n",
            "Loading: dandelion\n",
            "Loading: .ipynb_checkpoints\n",
            "Loading: tulips\n",
            "Loading: roses\n",
            "loaded 3670  samples\n",
            "classes {'sunflowers', 'daisy', 'dandelion', 'roses', 'tulips'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1IAtJPyO-nE",
        "outputId": "b6286fd2-3a83-4593-f247-5957f15e88ff"
      },
      "source": [
        "\n",
        "encoder = sklearn.preprocessing.LabelEncoder() # encoder\n",
        "intlabels = encoder.fit_transform(labels)\n",
        "labels = tf.keras.utils.to_categorical(intlabels)\n",
        "print(\"One-hot labels\",labels[:657])\n",
        "\n",
        "## find text label for label\n",
        "label = np.array([0,1])\n",
        "print('Label:',label)\n",
        "print(\"Text label:\",encoder.inverse_transform(label)) # WRONG! each value treated independently!\n",
        "print('argmax label:',label.argmax())\n",
        "#print(encoder.inverse_transform(label.argmax())) # encoder expects colection of values!\n",
        "print(\"Text label:\",encoder.inverse_transform([label.argmax()])) # works when packed into a collection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot labels [[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n",
            "Label: [0 1]\n",
            "Text label: ['daisy' 'dandelion']\n",
            "argmax label: 1\n",
            "Text label: ['dandelion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUihJ8fFP8Wk",
        "outputId": "2fda68c1-4627-4601-e011-6045b21516c9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\",input_shape=(64,64,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(4))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 16)        448       \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               4194816   \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 2052      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4202148 (16.03 MB)\n",
            "Trainable params: 4202052 (16.03 MB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA8MM5lRP9Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77894a81-7495-41ad-c4c2-cd27fe59e077"
      },
      "source": [
        "image_size = tuple((64, 64))\n",
        "\n",
        "def load_img(indir):\n",
        "    smp = []\n",
        "    labels = []\n",
        "    for class_dir in os.listdir(indir):\n",
        "        the_class = class_dir\n",
        "        for file in os.listdir(indir+'/'+class_dir):\n",
        "            image = cv2.imread(\"{}/{}/{}\".format(indir,class_dir,file))\n",
        "            image = cv2.resize(image, image_size)\n",
        "            smp.append(image)\n",
        "            labels.append(the_class)\n",
        "    smp = np.array(smp)\n",
        "    labels = np.array(labels)\n",
        "    return smp,labels\n",
        "smp, labels = load_img('flower_photos')\n",
        "smp,labels = sklearn.utils.shuffle(smp,labels)\n",
        "print('loaded',len(smp),' samples')\n",
        "print('classes',set(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded 3670  samples\n",
            "classes {'sunflowers', 'daisy', 'dandelion', 'roses', 'tulips'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPYLY6WJBJOH"
      },
      "source": [
        "import mahotas\n",
        "\n",
        "\n",
        "# feature-descriptor-1: Hu Moments\n",
        "def fd_hu_moments(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature\n",
        "\n",
        "def fd_haralick(image):\n",
        "    # convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # compute the haralick texture feature vector\n",
        "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
        "    return haralick\n",
        "\n",
        "def fd_histogram(image, mask=None):\n",
        "    bins=8\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    # compute the color histogram\n",
        "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "    # normalize the histogram\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO3_A1kEBOuN",
        "outputId": "1ab5c8b8-53ae-4ebc-df77-86183b1af535"
      },
      "source": [
        "new_samples = []\n",
        "for i,image in enumerate(smp):\n",
        "    fv_hu_moments = fd_hu_moments(image)\n",
        "    fv_haralick   = fd_haralick(image)\n",
        "    fv_histogram  = fd_histogram(image)\n",
        "    if(i%500==0): print(i,'/',len(smp))\n",
        "    features = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
        "    new_samples.append(features)\n",
        "smp = np.array(new_samples)\n",
        "#np.savetxt('samples.csv',fsamples) #save it if you want to reuse it!\n",
        "print(smp.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 3670\n",
            "500 / 3670\n",
            "1000 / 3670\n",
            "1500 / 3670\n",
            "2000 / 3670\n",
            "2500 / 3670\n",
            "3000 / 3670\n",
            "3500 / 3670\n",
            "(3670, 532)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uVwccOWBR_C",
        "outputId": "14b637f6-d62a-4a2b-ff21-62fe2f3b98c9"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "print(np.min(smp),np.max(smp))\n",
        "smp = scaler.fit_transform(smp)\n",
        "print(np.min(smp),np.max(smp))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.6241640388357443 42116.99917305573\n",
            "0.0 1.0000000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNn6-QrSBkII",
        "outputId": "4c19bd48-7bb2-4b0b-e78e-41f9d80d2a00"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = np.array(labels,dtype=float)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3670, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-a-Bn4ODUb2",
        "outputId": "dd983274-c6ae-4ee3-bb02-5f21382cac9a"
      },
      "source": [
        "dense_model = Sequential()\n",
        "dense_model.add(Dense(250, input_dim=532, activation='relu'))\n",
        "dense_model.add(Dense(250, activation='relu'))\n",
        "dense_model.add(Dense(250, activation='relu'))\n",
        "dense_model.add(Dense(5, activation='softmax'))\n",
        "dense_model.summary()\n",
        "#dense_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 250)               133250    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 250)               62750     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 250)               62750     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 1255      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 260005 (1015.64 KB)\n",
            "Trainable params: 260005 (1015.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PsArfmWDgCk"
      },
      "source": [
        "#from tensorflow.python.keras.models import Model\n",
        "Model = tf.keras.models.Model\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pboTK12BDqgI",
        "outputId": "932a3fb6-6d7c-4640-9b78-bd8d83c3a5af"
      },
      "source": [
        "combined = concatenate([model.output, dense_model.output])\n",
        "combined = Dense(16, activation=\"sigmoid\")(combined)\n",
        "combined = Dense(5, activation=\"sigmoid\")(combined)\n",
        "\n",
        "mod = Model(inputs=[model.input, dense_model.input], outputs=combined)\n",
        "\n",
        "print(mod.summary())\n",
        "\n",
        "mod.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " conv2d_4_input (InputLayer  [(None, 64, 64, 3)]          0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 16)           448       ['conv2d_4_input[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 16)           64        ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 64, 64, 16)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 32, 32, 16)           0         ['activation_8[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)           4640      ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 32)           128       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 32, 32, 32)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 16, 16, 32)           0         ['activation_9[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 16, 16, 32)           0         ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 8192)                 0         ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_12_input (InputLayer  [(None, 532)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 512)                  4194816   ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 250)                  133250    ['dense_12_input[0][0]']      \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 512)                  0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 250)                  62750     ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 4)                    2052      ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 250)                  62750     ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 4)                    0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 5)                    1255      ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 9)                    0         ['activation_11[0][0]',       \n",
            " )                                                                   'dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 16)                   160       ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 5)                    85        ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4462398 (17.02 MB)\n",
            "Trainable params: 4462302 (17.02 MB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE-XofdHEdzo",
        "outputId": "e6169b58-24df-46c6-ea92-d8ea7c743c7c"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH=100\n",
        "mod.fit([samples,smp], labels, batch_size=BATCH, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7a564b14dea0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7a564b14dea0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "37/37 [==============================] - 23s 522ms/step - loss: 1.6330 - accuracy: 0.2177\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 19s 514ms/step - loss: 1.5717 - accuracy: 0.3153\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 21s 577ms/step - loss: 1.5490 - accuracy: 0.3221\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 18s 498ms/step - loss: 1.5304 - accuracy: 0.3332\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 18s 497ms/step - loss: 1.5094 - accuracy: 0.4245\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 19s 514ms/step - loss: 1.4865 - accuracy: 0.4632\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 20s 522ms/step - loss: 1.4602 - accuracy: 0.4809\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 18s 499ms/step - loss: 1.4375 - accuracy: 0.4864\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 19s 517ms/step - loss: 1.4050 - accuracy: 0.5425\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 20s 551ms/step - loss: 1.3708 - accuracy: 0.5659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a564bd39810>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN9h2K0bFlA-",
        "outputId": "7e1c097b-c3d8-496a-81f0-93708a2b2c85"
      },
      "source": [
        "results1 = mod.predict([samples,smp])\n",
        "print(confusion_matrix(labels.argmax(axis=1), results1.argmax(axis=1)))\n",
        "print(classification_report(labels.argmax(axis=1), results1.argmax(axis=1)))\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy_score(labels.argmax(axis=1), results1.argmax(axis=1))))\n",
        "print(\"Cohen's Kappa {:.2f}\".format(cohen_kappa_score(labels.argmax(axis=1), results1.argmax(axis=1))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7a564bc0ea70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7a564bc0ea70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "115/115 [==============================] - 7s 55ms/step\n",
            "[[  0 382  16 194  41]\n",
            " [  0 761  31  90  16]\n",
            " [  0 128 290  36 187]\n",
            " [  0  67   0 603  29]\n",
            " [  0 101  89 113 496]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       633\n",
            "           1       0.53      0.85      0.65       898\n",
            "           2       0.68      0.45      0.54       641\n",
            "           3       0.58      0.86      0.70       699\n",
            "           4       0.64      0.62      0.63       799\n",
            "\n",
            "    accuracy                           0.59      3670\n",
            "   macro avg       0.49      0.56      0.50      3670\n",
            "weighted avg       0.50      0.59      0.52      3670\n",
            "\n",
            "Accuracy: 0.59\n",
            "Cohen's Kappa 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}